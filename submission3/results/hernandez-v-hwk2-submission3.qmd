---
title: "Homework 2"
author: "Valerie Hernandez"
format:
  pdf:
    toc: true
    toc-depth: 2
    number-sections: true
    colorlinks: true
    fig-width: 8
    fig-height: 6
    margin-left: 1in
    margin-right: 1in
    margin-top: 1in
    margin-bottom: 1in
execute:
  echo: false
  warning: false
  message: false
jupyter: python3
---

\newpage

**GitHub Repository:** git@github.com:valerie-hdz/homework2.git

---

# Part 1: Summarize the Data (2014-2019)

This section analyzes Medicare Advantage plan and service area data from 2014 through 2019.

## Question 1: Distribution of Plan Counts by County

After removing SNPs, 800-series plans, and prescription drug only plans, I analyzed the distribution of plan counts across counties over time.

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load all years of plan data
plan_data_list = []
for year in range(2014, 2020):
    df = pd.read_csv(f"../../../data/output/ma_data_{year}.csv")
    df['year'] = year
    plan_data_list.append(df)

all_plans = pd.concat(plan_data_list, ignore_index=True)

# Count plans by county and year
plan_counts = (
    all_plans
    .groupby(['fips', 'year'])
    .size()
    .reset_index(name='plan_count')
)

# Summary statistics
summary_stats = plan_counts.groupby('year')['plan_count'].describe()
print("Plan Count Distribution by Year:")
print(summary_stats.round(2))

# Store values for interpretation
median_count = plan_counts['plan_count'].median()
mean_count = plan_counts['plan_count'].mean()
p75_count = plan_counts['plan_count'].quantile(0.75)
max_count = plan_counts['plan_count'].max()
min_count = plan_counts['plan_count'].min()

print(f"\nOverall Statistics:")
print(f"Median plans per county: {median_count:.1f}")
print(f"Mean plans per county: {mean_count:.1f}")
print(f"75th percentile: {p75_count:.1f}")
print(f"Max plans: {max_count:.0f}")
```

![Distribution of Plan Counts by County (2014-2019)](../../../data/output/question1_plan_counts_boxplot.png)

**Interpretation:** 
The number of plans appears to be sufficient for most counties but potentially too few in rural areas. While urban counties have competition with 20+ plans, some rural counties have very limited choices such as fewer than 5 plans, which could limit beneficiary options and reduce competitive pressure on pricing and quality.

\newpage

## Question 2: Distribution of Plan Bids (2014 vs 2018)

Using the landscape files and risk/rebate data to calculate plan bids, I compared the distribution of bids between 2014 and 2018.

```{python}
# Load bid data for 2014 and 2018
bid_2014 = pd.read_csv("../../../data/output/ma_data_enhanced_2014.csv")
bid_2018 = pd.read_csv("../../../data/output/ma_data_enhanced_2018.csv")

bid_col = 'bid'

print("2014 Bid Statistics:")
print(bid_2014[bid_col].describe().round(2))

print("\n2018 Bid Statistics:")
print(bid_2018[bid_col].describe().round(2))

mean_2014 = bid_2014[bid_col].mean()
mean_2018 = bid_2018[bid_col].mean()
median_2014 = bid_2014[bid_col].median()
median_2018 = bid_2018[bid_col].median()
std_2014 = bid_2014[bid_col].std()
std_2018 = bid_2018[bid_col].std()

print(f"\nKey Changes:")
print(f"Mean bid: ${mean_2014:.2f} (2014) -> ${mean_2018:.2f} (2018), Change: ${mean_2018-mean_2014:.2f}")
print(f"Median bid: ${median_2014:.2f} -> ${median_2018:.2f}, Change: ${median_2018-median_2014:.2f}")
print(f"Std dev: ${std_2014:.2f} -> ${std_2018:.2f}, Change: ${std_2018-std_2014:.2f}")
```

![Distribution of Plan Bids: 2014 vs 2018](../../../data/output/bid_histograms_2014_2018.png)

**How the distribution has changed:**

The mean bid increased from approximately \$798 in 2014 to \$854 in 2018, representing a \$56 increase. The distribution became more dispersed, with the standard deviation increasing from \$178 to \$195. Both distributions remain relatively symmetric with a slight right skew, but the 2018 distribution shows more high-bid outliers. The upward shift suggests an overall cost growth in Medicare Advantage, potentially driven by increasing health care costs.

\newpage

## Question 3: Average HHI Over Time

Plot the average HHI over time from 2014 through 2019. How has the HHI changed over time? To measure HHI, you'll also need to incorporate the Medicare Advantage penetration files.

```{python}
hhi_results = pd.read_csv("../../../data/output/avg_hhi_by_year.csv")

print("Average HHI by Year:")
print(hhi_results[['year', 'avg_hhi', 'median', 'std', 'n_counties']].round(2))

hhi_2014 = hhi_results[hhi_results['year'] == 2014]['avg_hhi'].values[0]
hhi_2019 = hhi_results[hhi_results['year'] == 2019]['avg_hhi'].values[0]
hhi_change = hhi_2019 - hhi_2014
hhi_pct_change = (hhi_change / hhi_2014) * 100

print(f"\nChange from 2014 to 2019:")
print(f"2014 HHI: {hhi_2014:.2f}")
print(f"2019 HHI: {hhi_2019:.2f}")
print(f"Absolute change: {hhi_change:+.2f}")
print(f"Percent change: {hhi_pct_change:+.2f}%")
```

![Average HHI Over Time (2014-2019)](../../../data/output/question3_hhi.png)

**Analysis:**

The average HHI increased from 2,675 in 2014 to 2,838 in 2019 (6.1% growth). Throughout this period, the market remained "highly concentrated" (HHI >= 2,500). The increasing concentration indicates fewer plans are controlling larger shares of enrollment. Despite growing MA enrollment, markets became more concentrated rather than more competitive, suggesting industry consolidation.

\newpage

## Question 4: Medicare Advantage Penetration Over Time

Plot the average share of Medicare Advantage over time from 2014 to 2019. Has MA increased or decreased in popularity?

```{python}
ma_results = pd.read_csv("../../../data/output/ma_share_by_year.csv")

print("MA Penetration by Year:")
print(ma_results[['year', 'ma_share', 'total_eligibles', 'total_enrolled']].round(2))

ma_2014 = ma_results[ma_results['year'] == 2014]['ma_share'].values[0]
ma_2019 = ma_results[ma_results['year'] == 2019]['ma_share'].values[0]
ma_change = ma_2019 - ma_2014
ma_relative_change = (ma_change / ma_2014) * 100

print(f"\nChange from 2014 to 2019:")
print(f"2014: {ma_2014:.2f}%")
print(f"2019: {ma_2019:.2f}%")
print(f"Absolute change: {ma_change:+.2f} percentage points")
print(f"Relative growth: {ma_relative_change:+.2f}%")
```

![Medicare Advantage Penetration Rate (2014-2019)](../../../data/output/question4_ma_share.png)

**Has Medicare Advantage increased or decreased in popularity?**

Medicare Advantage has increased in popularity. Enrollment grew from 30.5% in 2014 to 36.8% in 2019, a 6.3 percentage point increase. This substantial growth demonstrates beneficiaries are increasingly choosing MA plans over traditional Medicare.

\newpage

# Part 2: Estimate Average Treatment Effects (2018 Only)
# Part 2: Estimate Average Treatment Effects (2018 Only)
```{python}
import pandas as pd
import numpy as np
import statsmodels.formula.api as smf
from sklearn.neighbors import NearestNeighbors

# Load plan-level MA data (2018 only)
county_df = pd.read_csv("../../../data/output/ma_data_enhanced_2018.csv", low_memory=False)
county_df = county_df[county_df["year"] == 2018].copy()

# Load FFS Excel file
ffs_raw = pd.read_excel(
    "../../../data/input/ffs_2018/FFS18.xlsx",
    skiprows=2,
    names=[
        "ssa", "state", "county_name",
        "parta_enroll", "parta_reimb", "parta_percap",
        "parta_reimb_unadj", "parta_percap_unadj",
        "parta_ime", "parta_dsh", "parta_gme",
        "partb_enroll", "partb_reimb", "partb_percap"
    ],
    na_values="*"
)

# Clean FFS data
final_ffs_costs = (
    ffs_raw[
        ["ssa", "state", "county_name",
         "parta_enroll", "parta_reimb",
         "partb_enroll", "partb_reimb"]
    ]
    .assign(year=2018, mean_risk=np.nan)
)

for col in ["ssa", "parta_enroll", "parta_reimb", "partb_enroll", "partb_reimb"]:
    final_ffs_costs[col] = pd.to_numeric(final_ffs_costs[col], errors="coerce")

# Merge FFS into plan-level data
county_df["ssa"] = pd.to_numeric(county_df["ssa"], errors="coerce")
final_ffs_costs["ssa"] = pd.to_numeric(final_ffs_costs["ssa"], errors="coerce")
final_ffs_costs["year"] = 2018

county_df = county_df.merge(final_ffs_costs, on=["ssa", "year"], how="left")

# Compute market share: plan enrollment / total county enrollment
county_totals = (
    county_df
    .groupby("fips")["enrollment"]
    .sum()
    .reset_index()
    .rename(columns={"enrollment": "county_total_enrollment"})
)

county_df = county_df.merge(county_totals, on="fips", how="left")
county_df["market_share_pct"] = (county_df["enrollment"] / county_df["county_total_enrollment"]) * 100

# Compute HHI per county (sum of squared market shares)
county_df["market_share_sq"] = county_df["market_share_pct"] ** 2

hhi_df = (
    county_df
    .groupby("fips")["market_share_sq"]
    .sum()
    .reset_index()
    .rename(columns={"market_share_sq": "hhi"})
)

# Aggregate to county level
county_agg = (
    county_df
    .groupby("fips")
    .agg(
        avg_bid=("bid", "mean"),
        avg_eligibles=("county_total_enrollment", "first")
    )
    .reset_index()
)

# FFS costs at county level
ffs_county = county_df[["fips", "parta_reimb", "partb_reimb"]].drop_duplicates("fips")

# Build final county-level dataframe
county_level = hhi_df.merge(county_agg, on="fips").merge(ffs_county, on="fips", how="left")

print(f"County-level observations: {len(county_level)}")
print(f"HHI range: {county_level['hhi'].min():.0f} - {county_level['hhi'].max():.0f}")

# ── Q5: Average bid by competitive vs uncompetitive ──────────────────────────
q_low  = county_level["hhi"].quantile(0.33)
q_high = county_level["hhi"].quantile(0.66)

county_level["treated_dummy"] = np.where(
    county_level["hhi"] >= q_high, 1,
    np.where(county_level["hhi"] <= q_low, 0, np.nan)
)

county_level = county_level.dropna(subset=["treated_dummy"]).copy()
county_level["treated_dummy"] = county_level["treated_dummy"].astype(int)

avg_bid_by_group = county_level.groupby("treated_dummy")["avg_bid"].mean()
print("\nQ5 - Average Bid by Group (0=Competitive, 1=Uncompetitive):")
print(avg_bid_by_group)

# ── Q6: Average bid by treatment and FFS quartile ────────────────────────────
county_level["ffs_total"] = county_level["parta_reimb"] + county_level["partb_reimb"]
county_level["ffs_q"] = pd.qcut(county_level["ffs_total"], 4, labels=False) + 1

for q in [1, 2, 3, 4]:
    county_level[f"ffs_q{q}"] = (county_level["ffs_q"] == q).astype(int)

quartile_table = (
    county_level
    .groupby(["ffs_q", "treated_dummy"])["avg_bid"]
    .mean()
    .unstack()
)
print("\nQ6 - Average Bid by FFS Quartile and Treatment:")
print(quartile_table)

# Load precomputed results
results = pd.read_csv("../../../data/output/ate_results.csv")
summary = pd.read_csv("../../../data/output/ate_summary.csv")

from IPython.display import display
display(results.style.format({"ATE": "{:.4f}"}))

ate_quartile_ols = summary[summary["estimator"] == "ATE (quartile dummies)"]["value"].values[0]
ate_continuous_ols = summary[summary["estimator"] == "ATE (continuous covariates)"]["value"].values[0]

print(f"ATE (continuous covariates): {ate_continuous_ols:.4f}")
print(f"ATE (quartile dummies):      {ate_quartile_ols:.4f}")

## Question 5: Average Bid Among Competitive vs Uncompetitive Markets

Competitive markets (lower 33rd percentile HHI) tend to have lower average bids than uncompetitive markets (upper 66th percentile HHI), consistent with theory that less competition leads to higher bids.

## Question 6: Average Bid by Treatment and FFS Quartile

The table above shows average bids broken down by FFS cost quartile and treatment group.

## Question 7: ATE Estimates

The four estimators produce very similar ATEs. While not perfectly identical, differences are small and arise from minor weighting and functional form differences. The conclusions are consistent across all methods.

## Question 8: Are the Results Similar Across Estimators?

The four estimators — nearest neighbor matching (Euclidean and Mahalanobis), inverse propensity weighting, and OLS regression — produce very similar estimated ATEs. While the numerical values are not perfectly identical, the differences are small and arise from minor weighting and functional form differences across methods. Substantively, the conclusions are the same, and the results are highly consistent.

## Question 9: OLS with Continuous Covariates

Using continuous FFS costs and total Medicare beneficiaries yields a very similar treatment effect to the quartile-based estimate, suggesting that discretizing FFS costs into quartiles does not materially change results. Minor differences reflect the additional flexibility gained from using continuous covariates.

\newpage

## Question 10: Reflection

One thing I learned is how to integrate multiple datasets across different geographic identifiers. One thing that was challenging was deciding how to organize my workflow and creating the merged 2014-2019 dataset.

**Repository:** git@github.com:valerie-hdz/homework2.git